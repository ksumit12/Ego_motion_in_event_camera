\chapter*{Abstract}

Event cameras sense per-pixel brightness changes asynchronously with microsecond latency and very high dynamic range, offering a promising alternative to conventional frame-based vision in robotics. However, during ego-motion even static scenes generate dense background events, mixing with true object-motion signals and creating bandwidth and processing overhead. Suppressing these predictable ego-motion events at the source could significantly reduce redundancy and improve efficiency in event-based perception.

This thesis explores a forward-prediction approach to cancel ego-motion events caused by rotational motion. Each event is propagated to a predicted future location using an estimated rotation centre and angular velocity, where an inverse-polarity event is emitted to suppress redundant observations. The system is designed to operate in real time without relying on batch accumulation or image reconstruction. Using a controlled spinning-disc dataset, cancellation performance was evaluated under varying parameters including prediction horizon, spatial and temporal tolerances, polarity handling, and model bias. Results demonstrate cancellation rates up to 84\% at short horizons, with sensitivity strongly linked to parameter choice and estimation accuracy. 

While current performance highlights limitations of simplified motion models and sensor noise characteristics, the study establishes a structured methodology for analysing residual event distributions and parameter effects. This provides a foundation for future extensions to general ego-motion, uncertainty-aware prediction, and hardware-efficient implementations aimed at enabling practical event-level suppression in robotics.
