\chapter{Motion Estimation \& Event Prediction}
\label{chap:motion}

\section{Purpose and Role in the Pipeline}
Accurate ego-motion estimation is the prerequisite for our per-event forward prediction and cancellation scheme (Chapter~\ref{chap:cancellation}). Since event cameras asynchronously report brightness changes along moving edges, the vast majority of events in a static scene under camera motion are caused by \emph{ego-motion} \cite{Gallego2020Survey}. Estimating the rotational motion parameters allows us to predict the short-horizon trajectories of events and issue anti-events when a causal spatio-temporal gate is satisfied (Chapter~\ref{chap:problem}). In this chapter we: (i) formalize the rotational model used for prediction; (ii) review estimation strategies from the literature; (iii) present our practical estimation pipeline tailored to a circular-motion rig; and (iv) analyze error sources and their impact on downstream cancellation.

\section{Background: Motion Estimation with Events}
Event-based motion estimation spans local differential methods, global alignment via motion compensation, and tightly-coupled state estimation with auxiliary sensing.

\paragraph{Local differential / plane-based flow.}
Local approaches estimate optical flow by fitting spatio-temporal event neighborhoods to motion models, exploiting the fact that edges generate approximately planar structures in $(x,y,t)$ volumes \cite{Benosman2014Epipolar}. These methods capture instantaneous flow but are sensitive to noise, aperture ambiguity, and require careful neighborhood selection.

\paragraph{Global contrast maximization \& IWE alignment.}
Global methods ``warp'' events to a common reference time with a candidate motion field and seek parameters that maximize an alignment objective (sharpness/contrast) of the \emph{Image of Warped Events} (IWE) \cite{Gallego2018CMax}. This paradigm underlies a broad family of algorithms for optical flow, depth, and ego-motion; its rotational specialization yields direct angular-velocity estimation from events \cite{Gallego2017Angular}. Event-based motion segmentation likewise leverages motion compensation in iterative schemes (e.g., EM) to jointly estimate multiple motion layers and their assignments \cite{Stoffregen2019Segmentation}.

\paragraph{Sliding-window variational estimation and learning.}
Bardow \emph{et al.} estimated optical flow and intensity jointly using a variational formulation over short temporal windows \cite{Bardow2016SOFIE}. Learning-based methods predict dense flow or depth/ego-motion from event tensors \cite{Zhu2018FlowNet,Zhu2019Unsupervised,Rebecq2019E2VID}, but typically target image reconstruction or downstream perception rather than explicit short-horizon forward prediction for cancellation.

\paragraph{VIO/SLAM and continuous-time estimation.}
Event-only and fused event–frame–IMU odometry methods estimate full 6-DoF trajectories in real time (e.g., continuous-time splines, tightly-coupled filters) \cite{Rebecq2017EVO,Gallego2018CMax,Niu2024TRO,Guo2024TRO}. While general and powerful, they introduce batch windows and optimization latencies that are at odds with our design goal of strictly \emph{causal, per-event} operation for proactive suppression.

\section{Rotational Motion Model for Short Horizons}
We model the dominant motion as planar rotation of the image around a center $c=(c_x,c_y)^\top$ with angular velocity $\omega$ (signed). Let $x=(x,y)^\top$ be a pixel coordinate (in pixels). The rotation operator about $c$ by angle $\theta$ is
\begin{equation}
\mathcal{R}(x; c, \theta) \;=\; c + R(\theta)\,(x-c), 
\qquad
R(\theta) = 
\begin{bmatrix}
\cos\theta & -\sin\theta\\
\sin\theta & \cos\theta
\end{bmatrix}.
\label{eq:rot-op}
\end{equation}
Over a short prediction horizon $\Delta t$, assuming constant angular velocity, the forward-predicted location of an event occurring at time $t$ and position $x$ is
\begin{equation}
x' \;=\; \mathcal{R}\!\left(x; c, \omega\,\Delta t\right).
\label{eq:forward-predict}
\end{equation}
Equation~\eqref{eq:forward-predict} is the geometric backbone of the predict–wait–match rule in Chapter~\ref{chap:problem}. Rotation-only models are widely used in event-based motion estimation and yield closed-form sensitivities, making them attractive for controlled rigs (e.g., spinning discs) and short-horizon prediction \cite{Gallego2017Angular,Gallego2018CMax,Stoffregen2019Segmentation}.

\paragraph{Normalized vs. pixel coordinates.}
If significant lens distortion or strong perspective effects are present, coordinates should be undistorted and normalized before applying \eqref{eq:rot-op}; in our setup, we work on calibrated or approximately linearized pixel coordinates, consistent with controlled planar rigs \cite{Scheerlinck2021Thesis,Wang2025Thesis}.

\section{From Events to Rotation Parameters}
\subsection{Problem Statement}
Given a stream of events $E=\{(x_i,t_i,p_i)\}$ from a static scene under ego-rotation, estimate $(c,\omega)$ as functions of time. Since we deploy predictions at the per-event timescale, we require estimates (or smoothed trajectories) that can be \emph{interpolated at arbitrary timestamps}.

\subsection{Estimation Strategies}
We discuss two complementary strategies suitable for our circular-motion setting.

\subsubsection{Direct angular velocity via contrast maximization}
A rotational specialization of contrast maximization warps events by a hypothesized angular velocity $\omega$ (and center $c$) to a common reference time and seeks the $\omega$ that maximizes IWE sharpness \cite{Gallego2017Angular,Gallego2018CMax}. Let $x_i$ be rotated backward from $t_i$ to $t_0$ by angle $\omega\,(t_i-t_0)$ about $c$, producing $x_i(t_0)$; then the IWE is $I(x;t_0) = \sum_i \kappa(x - x_i(t_0))\,\sigma_i$, with $\kappa(\cdot)$ a smoothing kernel and $\sigma_i\in\{\pm 1\}$ the polarity. Common objectives are variance or contrast of $I$. Optimization can be performed over short packets (e.g., a few milliseconds), yielding a quasi-instantaneous $\hat\omega$ \cite{Gallego2018CMax}. This approach is robust to noise at adequate event densities and ties directly to rotational flow.

\subsubsection{Circle fitting and angle-differencing}
When a high-contrast rim or marker on a spinning disc produces coherent event clusters, we may fit circles to spatial event clouds to estimate $c$ and radial trajectories. Consider a set of event coordinates $\{x_k\}$ accumulated over a very short window $\Delta T$ (small enough for negligible rotation of $c$). Define the algebraic circle fit objective
\begin{equation}
\min_{c,r}\;\sum_{k}\left(\|x_k - c\|_2 - r\right)^2,
\label{eq:circlefit}
\end{equation}
which admits stable solutions via Pratt/Taubin variants or RANSAC for outlier rejection (the specific variant is implementation-dependent). With $c$ estimated, each event location $x_k$ yields a \emph{bearing angle} $\theta_k = \mathrm{atan2}(y_k-c_y,\;x_k-c_x)$. Sorting by timestamps, a finite-difference estimate of angular velocity is
\begin{equation}
\hat\omega(t_k) \;\approx\; \frac{\mathrm{unwrap}\!\left(\theta_k-\theta_{k-1}\right)}{t_k - t_{k-1}},
\label{eq:angvel-diff}
\end{equation}
optionally smoothed by a causal filter (e.g., exponential moving average). This procedure exploits the geometric structure of circular motion and avoids packet-wise optimization, at the cost of sensitivity to center bias and sparse sampling.

\subsection{Interpolation and Time Alignment}
Our predictor requires $(\hat c(t),\hat\omega(t))$ at the \emph{exact} event times $t_i$. We therefore store time series $\{\hat c(t_m),\hat\omega(t_m)\}$ at estimation timestamps $\{t_m\}$ and evaluate them at arbitrary $t$ by 1D interpolation:
\begin{equation}
\hat c(t) \!=\! \mathrm{interp1}\!\left(t;\{t_m\},\{\hat c(t_m)\}\right),\quad
\hat\omega(t) \!=\! \mathrm{interp1}\!\left(t;\{t_m\},\{\hat\omega(t_m)\}\right).
\label{eq:interp}
\end{equation}
In practice, linear interpolation with edge hold is sufficient given our sub-millisecond horizons and smoothly varying $\omega(t)$ on the rig. When available, an external tracker (e.g., blob tracker or encoder) can provide $\{(t_m,\hat c,\hat\omega)\}$ directly, which we then interpolate at event timestamps. Using IMU gyroscope as a \emph{feed-forward} prior on $\omega$ is also common in event tracking \cite{Rebecq2017EVO,Wang2025Thesis}.

\section{Event Prediction under Rotation}
Given an event $e_i=(x_i,t_i,p_i)$, the forward prediction for a horizon $\Delta t$ applies \eqref{eq:forward-predict} with the \emph{time-aligned} parameters:
\begin{equation}
x_i' \;=\; \mathcal{R}\!\left(x_i;\;\hat c(t_i),\;\hat\omega(t_i)\,\Delta t\right), 
\qquad t_i' \;=\; t_i + \Delta t,
\label{eq:per-event-predict}
\end{equation}
yielding the predicted future location and decision time. These predicted tuples $\hat e_i=(x_i',t_i',\bar p_i)$ feed the spatio-temporal gate in Chapter~\ref{chap:problem}. Because $\Delta t$ is short (typically $\leq$ a few milliseconds), assuming piecewise-constant $\omega$ over $[t_i,t_i+\Delta t]$ is reasonable for rigs with slowly varying spin rate \cite{Gallego2017Angular,Scheerlinck2021Thesis}. The choice of $\Delta t$ trades phase separation (too small $\Delta t$ $\Rightarrow$ insufficient temporal separation) versus sensitivity to parameter bias (too large $\Delta t$ $\Rightarrow$ larger spatial mismatch), as quantified next.

\section{Error Sources and Sensitivity}
Let the true parameters be $(c^\star,\omega^\star)$ and the estimates $(\hat c,\hat\omega)$. For a point at radius $r=\|x_i-c^\star\|_2$, the spatial prediction error after $\Delta t$ decomposes into (i) angular-velocity error, (ii) center bias, and (iii) timing uncertainty.

\paragraph{Angular-velocity bias.}
With $\Delta\omega = \hat\omega-\omega^\star$, the predicted angle differs by $\delta\theta = \Delta\omega\,\Delta t$. The spatial error on the circle of radius $r$ is
\begin{equation}
\varepsilon_{\omega}(r,\Delta t) 
\;=\; 2r\,\big|\sin(\delta\theta/2)\big| 
\;\approx\; r\,|\Delta\omega|\,\Delta t,
\label{eq:err-omega}
\end{equation}
for small $\delta\theta$ (first-order approximation). This linear dependence explains the degradation in cancellation as either $r$ or $\Delta t$ grows for a fixed $\Delta\omega$.

\paragraph{Center-of-rotation bias.}
If $\Delta c = \hat c - c^\star$, then even with perfect $\omega$ the rotation is applied about the wrong center, causing a position error with a dominant, roughly radius-independent component
\begin{equation}
\varepsilon_c(r) \;\lesssim\; \|\Delta c\|_2,
\label{eq:err-center}
\end{equation}
which couples with \eqref{eq:err-omega} when both errors are present. In practice, center bias manifests as a radius-dependent residual structure in cancellation outputs.

\paragraph{Timing uncertainty and temporal gating.}
Let $\sigma_t$ capture effective temporal uncertainty (timestamp quantization, readout delays). Over horizon $\Delta t$, the phase uncertainty is $\sigma_\theta \approx |\omega^\star|\,\sigma_t$, producing spatial uncertainty $\sigma_x \approx r\,\sigma_\theta$. Hence, increasing $\Delta t$ separates prediction and observation in time (useful for gating) but increases phase error for a fixed $\Delta\omega$; decreasing $\Delta t$ reduces phase error but also shrinks the temporal gate and may cause overlap with predictor latency. These effects motivate the temporal gate $|t_j-(t_i+\Delta t)|\le \epsilon_t$ in Chapter~\ref{chap:problem} and the parameter sweeps in Chapter~\ref{chap:metrics}.

\paragraph{Implications for cancellation.}
A sufficient condition for a successful match is
\begin{equation}
\varepsilon_{\omega}(r,\Delta t) + \varepsilon_c(r) + \sigma_x \;\le\; \epsilon_{xy},
\label{eq:gate-sufficient}
\end{equation}
which captures how (\emph{i}) accurate $\hat\omega$ matters more at large radii and large $\Delta t$, and (\emph{ii}) small center biases translate into a uniform error floor limiting achievable cancellation even at small $\Delta t$. These dependencies are consistent with the alignment principles in event warping \cite{Gallego2018CMax} and motion segmentation via compensation \cite{Stoffregen2019Segmentation}.

\section{Our Practical Estimation Pipeline}
\label{sec:our-pipeline}
We adopt a pragmatic pipeline tailored to the disc rig and asynchronous cancellation:

\subsection*{(1) Event collection and short-window accumulation}
Events are processed in short, overlapping windows (e.g., a few milliseconds) to form sparse spatial clouds suitable for circle fitting or to drive rotational contrast maximization when a stable rim/marker is present. Window length balances spatial support (too small $\Rightarrow$ sparse) and motion stationarity (too large $\Rightarrow$ parameter drift).

\subsection*{(2) Center estimation via circle fitting}
We solve \eqref{eq:circlefit} on the accumulated cloud using a robust algebraic fit (Pratt/Taubin) with optional RANSAC to mitigate outliers from background activity and edge fragments. The resulting $\hat c$ is smoothed over time with a causal low-pass filter.

\subsection*{(3) Angular velocity estimation}
Two interchangeable routes are used:
\begin{itemize}
\item \emph{IWE-based specialization:} Optimize $\omega$ by maximizing IWE contrast over the short window for the current $\hat c$ \cite{Gallego2017Angular,Gallego2018CMax}. This is robust when event density is high and edges are well-distributed.
\item \emph{Angle differencing:} Compute angles $\theta_k$ around $\hat c$ and evaluate \eqref{eq:angvel-diff} with causal smoothing. This is lightweight and well-matched to strong circular structure.
\end{itemize}
When available, an external tracker or gyroscope prior provides $\tilde\omega$, which we fuse by exponential averaging:
\begin{equation}
\hat\omega(t_k) \leftarrow (1-\alpha)\,\hat\omega(t_{k^-}) + \alpha\,\tilde\omega(t_k),\qquad \alpha\in(0,1],
\label{eq:ema}
\end{equation}
trading responsiveness for noise attenuation \cite{Rebecq2017EVO}.

\subsection*{(4) Interpolation to event times}
We store $\{\hat c(t_m),\hat\omega(t_m)\}$ and evaluate \eqref{eq:interp} at \emph{every} event time $t_i$ before applying \eqref{eq:per-event-predict}. This preserves causality and avoids batching, aligning with our per-event cancellation design.

\subsection*{(5) Sanity checks and fast diagnostics}
As an online diagnostic, we monitor an IWE sharpness proxy and a \emph{radial residual profile} (after cancellation) to detect center bias (flat offset) and angular-velocity drift (radius-dependent widening). Such diagnostics mirror the role of contrast objectives in \cite{Gallego2018CMax} and the alignment criteria in segmentation-by-compensation \cite{Stoffregen2019Segmentation}.

\section{Validation and Bridge to Experiments}
We validate $(\hat c,\hat\omega)$ in two ways. First, when an external tracker is used, we compare $\hat\omega$ to the tracker's angular velocity (or to a derived encoder ground truth) and report absolute and relative errors over time. Second, we assess \emph{functional} quality via downstream metrics: cancellation ratio, residual density on background vs.\ disc masks, and radial residual profiles (Chapter~\ref{chap:metrics}). Improvements in these metrics under consistent gating settings indicate better short-horizon alignment, consistent with event-warping principles \cite{Gallego2018CMax}.

\section{Discussion and Limitations}
Rotation-only modeling simplifies short-horizon prediction and supports causal operation, but suffers when translation is non-negligible or the rotation center drifts. In such cases, adding a weak translation term or fusing gyroscope priors can stabilize $\hat\omega$ and reduce phase error \cite{Rebecq2017EVO}. Learning-based estimators could supply priors for $\hat c$ or refine $\hat\omega$, but would likely introduce latency and dependence on training distributions \cite{Zhu2018FlowNet,Zhu2019Unsupervised}. Our emphasis remains on lightweight, analyzable estimation that integrates cleanly with per-event cancellation.

\medskip
\noindent\textbf{Summary.} This chapter presented a rotation-only motion model for short-horizon prediction, reviewed estimation strategies with events, and described a practical, causal pipeline to produce time-aligned $(\hat c,\hat\omega)$ for per-event forward prediction. The next chapter details the cancellation rule and implementation, and Chapter~\ref{chap:metrics} quantifies sensitivity to $\Delta t$, spatial/temporal tolerances, and parameter biases.
