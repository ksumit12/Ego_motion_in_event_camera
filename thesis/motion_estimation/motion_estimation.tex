\chapter{Motion Estimation \& Event Prediction}
\label{chap:motion}

\section{Purpose and Role in the Pipeline}
Accurate ego-motion estimation is the prerequisite for our per-event forward prediction and cancellation scheme (Chapter~\ref{chap:cancellation}). Since event cameras asynchronously report brightness changes along moving edges, the vast majority of events in a static scene under camera motion are caused by \emph{ego-motion} \cite{Gallego2020Survey}. Estimating the rotational motion parameters allows us to predict the short-horizon trajectories of events and issue anti-events when a causal spatio-temporal gate is satisfied (Chapter~\ref{chap:problem}). In this chapter we: (i) formalize the rotational model used for prediction; (ii) review estimation strategies from the literature; (iii) present our practical estimation pipeline tailored to a circular-motion rig; and (iv) analyze error sources and their impact on downstream cancellation.


\section{Rotational Motion Model for Short Horizons}
We model the dominant motion as planar rotation of the image around a center $c=(c_x,c_y)^\top$ with angular velocity $\omega$ (signed). Let $x=(x,y)^\top$ be a pixel coordinate (in pixels). The rotation operator about $c$ by angle $\theta$ is
\begin{equation}
\mathcal{R}(x; c, \theta) \;=\; c + R(\theta)\,(x-c), 
\qquad
R(\theta) = 
\begin{bmatrix}
\cos\theta & -\sin\theta\\
\sin\theta & \cos\theta
\end{bmatrix}.
\label{eq:rot-op}
\end{equation}
Over a short prediction horizon $\Delta t$, assuming constant angular velocity, the forward-predicted location of an event occurring at time $t$ and position $x$ is
\begin{equation}
x' \;=\; \mathcal{R}\!\left(x; c, \omega\,\Delta t\right).
\label{eq:forward-predict}
\end{equation}
Equation~\eqref{eq:forward-predict} is the geometric backbone of the predict–wait–match rule in Chapter~\ref{chap:problem}. Rotation-only models are widely used in event-based motion estimation and yield closed-form sensitivities, making them attractive for controlled rigs (e.g., spinning discs) and short-horizon prediction \cite{Gallego2017Angular,Gallego2018CMax,Stoffregen2019Segmentation}.

\paragraph{Normalized vs. pixel coordinates.}
If significant lens distortion or strong perspective effects are present, coordinates should be undistorted and normalized before applying \eqref{eq:rot-op}; in our setup, we work on calibrated or approximately linearized pixel coordinates, consistent with controlled planar rigs \cite{Scheerlinck2021Thesis,Wang2025Thesis}.

\section{From Events to Rotation Parameters}
\subsection{Problem Statement}
Given a stream of events $E=\{(x_i,t_i,p_i)\}$ from a static scene under ego-rotation, estimate $(c,\omega)$ as functions of time. Since we deploy predictions at the per-event timescale, we require estimates (or smoothed trajectories) that can be \emph{interpolated at arbitrary timestamps}.

\subsection{Estimation Strategy}
We use \emph{circle fitting with angle differencing} as our motion-estimation method for the circular-motion setting.

\subsubsection{Direct angular velocity via contrast maximization}
A rotational specialization of contrast maximization warps events by a hypothesized angular velocity $\omega$ (and center $c$) to a common reference time and seeks the $\omega$ that maximizes IWE sharpness \cite{Gallego2017Angular,Gallego2018CMax}. Let $x_i$ be rotated backward from $t_i$ to $t_0$ by angle $\omega\,(t_i-t_0)$ about $c$, producing $x_i(t_0)$; then the IWE is $I(x;t_0) = \sum_i \kappa(x - x_i(t_0))\,\sigma_i$, with $\kappa(\cdot)$ a smoothing kernel and $\sigma_i\in\{\pm 1\}$ the polarity. Common objectives are variance or contrast of $I$. Optimization can be performed over short packets (e.g., a few milliseconds), yielding a quasi-instantaneous $\hat\omega$ \cite{Gallego2018CMax}. This approach is robust to noise at adequate event densities and ties directly to rotational flow.

\subsubsection{Circle fitting and angle-differencing}
When a high-contrast rim or marker on a spinning disc produces coherent event clusters, we may fit circles to spatial event clouds to estimate $c$ and radial trajectories. Consider a set of event coordinates $\{x_k\}$ accumulated over a very short window $\Delta T$ (small enough for negligible rotation of $c$). Define the algebraic circle fit objective
\begin{equation}
\min_{c,r}\;\sum_{k}\left(\|x_k - c\|_2 - r\right)^2,
\label{eq:circlefit}
\end{equation}
which admits stable solutions via Pratt/Taubin variants or RANSAC for outlier rejection (the specific variant is implementation-dependent). With $c$ estimated, each event location $x_k$ yields a \emph{bearing angle} $\theta_k = \mathrm{atan2}(y_k-c_y,\;x_k-c_x)$. Sorting by timestamps, a finite-difference estimate of angular velocity is
\begin{equation}
\hat\omega(t_k) \;\approx\; \frac{\mathrm{unwrap}\!\left(\theta_k-\theta_{k-1}\right)}{t_k - t_{k-1}},
\label{eq:angvel-diff}
\end{equation}
optionally smoothed by a causal filter (e.g., exponential moving average). This procedure exploits the geometric structure of circular motion and avoids packet-wise optimization, at the cost of sensitivity to center bias and sparse sampling.

\subsection{Interpolation and Time Alignment}
Our predictor requires $(\hat c(t),\hat\omega(t))$ at the \emph{exact} event times $t_i$. We therefore store time series $\{\hat c(t_m),\hat\omega(t_m)\}$ at estimation timestamps $\{t_m\}$ and evaluate them at arbitrary $t$ by 1D interpolation:
\begin{equation}
\hat c(t) \!=\! \mathrm{interp1}\!\left(t;\{t_m\},\{\hat c(t_m)\}\right),\quad
\hat\omega(t) \!=\! \mathrm{interp1}\!\left(t;\{t_m\},\{\hat\omega(t_m)\}\right).
\label{eq:interp}
\end{equation}
In practice, linear interpolation with edge hold is sufficient given our sub-millisecond horizons and smoothly varying $\omega(t)$ on the rig. When available, an external tracker (e.g., blob tracker or encoder) can provide $\{(t_m,\hat c,\hat\omega)\}$ directly, which we then interpolate at event timestamps. An asynchronous event-blob tracker can also supply high-rate motion cues \cite{Wang2024AEBTracker}. Using IMU gyroscope as a \emph{feed-forward} prior on $\omega$ is also common in event tracking \cite{Rebecq2017EVO,Wang2025Thesis}.

\section{Event Prediction under Rotation}
Given an event $e_i=(x_i,t_i,p_i)$, the forward prediction for a horizon $\Delta t$ applies \eqref{eq:forward-predict} with the \emph{time-aligned} parameters:
\begin{equation}
x_i' \;=\; \mathcal{R}\!\left(x_i;\;\hat c(t_i),\;\hat\omega(t_i)\,\Delta t\right), 
\qquad t_i' \;=\; t_i + \Delta t,
\label{eq:per-event-predict}
\end{equation}
and we adopt the predicted tuple
\[
e'_i = (x'_i,\,t'_i,\,p'_i),\quad p'_i = -p_i,
\]
matching the notation in Chapter~\ref{chap:problem}. These predicted events feed the spatio-temporal gate. Because $\Delta t$ is short (typically $\leq$ a few milliseconds), assuming piecewise-constant $\omega$ over $[t_i,t_i+\Delta t]$ is reasonable for rigs with slowly varying spin rate \cite{Gallego2017Angular,Scheerlinck2021Thesis}.

\section{Error Sources and Sensitivity (pointer)}
Error terms and gate-sizing are detailed once in Chapter~\ref{chap:problem} (Eqs.~\eqref{eq:angvel-error}--\eqref{eq:gate-condition}). Here we refer to that analysis to avoid repetition.

\section{Our Practical Estimation Pipeline}
\label{sec:our-pipeline}
We adopt a pragmatic pipeline tailored to the disc rig and asynchronous cancellation:

\subsection*{(1) Event collection and short-window accumulation}
Events are processed in short, overlapping windows (e.g., a few milliseconds) to form sparse spatial clouds suitable for circle fitting. Window length balances spatial support (too small $\Rightarrow$ sparse) and motion stationarity (too large $\Rightarrow$ parameter drift).

\subsection*{(2) Center estimation via circle fitting}
We solve \eqref{eq:circlefit} on the accumulated cloud using a robust algebraic fit (Pratt/Taubin) with optional RANSAC to mitigate outliers from background activity and edge fragments. The resulting $\hat c$ is smoothed over time with a causal low-pass filter.

\subsection*{(3) Angular velocity estimation}
We use \emph{angle differencing}: compute angles $\theta_k$ around $\hat c$ and evaluate \eqref{eq:angvel-diff} with causal smoothing. This is lightweight and well-matched to strong circular structure.
When available, an external tracker or gyroscope prior provides $\tilde\omega$, which we fuse by exponential averaging:
\begin{equation}
\hat\omega(t_k) \leftarrow (1-\alpha)\,\hat\omega(t_{k^-}) + \alpha\,\tilde\omega(t_k),\qquad \alpha\in(0,1],
\label{eq:ema}
\end{equation}
trading responsiveness for noise attenuation \cite{Rebecq2017EVO}.

\subsection*{(4) Interpolation to event times}
We store $\{\hat c(t_m),\hat\omega(t_m)\}$ and evaluate \eqref{eq:interp} at \emph{every} event time $t_i$ before applying \eqref{eq:per-event-predict}. This preserves causality and avoids batching, aligning with our per-event cancellation design.

\subsection*{(5) Sanity checks and fast diagnostics}
As an online diagnostic, we monitor a \emph{radial residual profile} (after cancellation) to detect center bias (flat offset) and angular-velocity drift (radius-dependent widening), mirroring alignment criteria in segmentation-by-compensation \cite{Stoffregen2019Segmentation}.

\section{Validation and Bridge to Experiments}
We validate $(\hat c,\hat\omega)$ in two ways. First, when an external tracker is used, we compare $\hat\omega$ to the tracker's angular velocity (or to a derived encoder ground truth) and report absolute and relative errors over time. Second, we assess \emph{functional} quality via downstream metrics: cancellation ratio, residual density on background vs.\ disc masks, and radial residual profiles (Chapter~\ref{chap:metrics}). Improvements in these metrics under consistent gating settings indicate better short-horizon alignment, consistent with event-warping principles \cite{Gallego2018CMax}.

\section{Discussion and Limitations}
Rotation-only modeling simplifies short-horizon prediction and supports causal operation, but suffers when translation is non-negligible or the rotation center drifts. In principle, handling translation requires either scene depth (or inverse depth) or restrictive assumptions (e.g., far-scene, planar scene) \cite{Gallego2020Survey,Gallego2018CMax,Rebecq2017EVO,Benosman2014Epipolar}. We therefore did not include translation in our implementation; on our rig and time horizons, rotation dominates the image motion. A possible extension is to include a small, regularized translation component under a far-scene/constant inverse-depth assumption as a prior (``weak translation''), but we leave this as future work \cite{Gallego2020Survey}. Gyroscope fusion can also stabilize $\hat\omega$ and reduce phase error \cite{Rebecq2017EVO}. Learning-based estimators could supply priors for $\hat c$ or refine $\hat\omega$, but would likely introduce latency and dependence on training distributions \cite{Zhu2018FlowNet,Zhu2019Unsupervised}. Our emphasis remains on lightweight, analyzable estimation that integrates cleanly with per-event cancellation.

\medskip
\noindent\textbf{Summary.} This chapter presented a rotation-only motion model for short-horizon prediction, reviewed estimation strategies with events, and described a practical, causal pipeline to produce time-aligned $(\hat c,\hat\omega)$ for per-event forward prediction. The next chapter details the cancellation rule and implementation, and Chapter~\ref{chap:metrics} quantifies sensitivity to $\Delta t$, spatial/temporal tolerances, and parameter biases.
